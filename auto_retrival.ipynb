{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values, load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "api_key = os.getenv('PRACTICE_KEY')\n",
    "langchain_api_key = os.getenv('LANGCHAIN_KEY')\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = langchain_api_key\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure output\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "Settings.embed_model = embed_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.elasticsearch import ElasticsearchStore\n",
    "\n",
    "\n",
    "\n",
    "es = ElasticsearchStore(\n",
    "    index_name=\"bhaiya_&_company\",\n",
    "    es_url=\"http://localhost:9200\",\n",
    ")\n",
    "\n",
    "vector_store  = ElasticsearchStore(\n",
    "    index_name=\"bhaiya_&_company\",\n",
    "    es_url=\"http://localhost:9200\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "# from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -qU langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    "    Document,\n",
    "    SimpleDirectoryReader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    "    StorageContext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_service_context(embedding):\n",
    "\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        llm=None,\n",
    "        embed_model=embedding,\n",
    "    )\n",
    "\n",
    "    return service_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama_index llama-index-llms-openai llama-index-indices-managed-vectara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhaiyasingh\\AppData\\Local\\Temp\\ipykernel_35464\\4018671484.py:3: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "service_context = load_service_context(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = es # vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.agents import AgentFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''You are a highly knowledgeable assistant for Bhaiya & Company, \n",
    "\n",
    "Given a user's question, your task is to generate a precise and informative response based on the relevant documents. Use the provided documents to ensure your answers are accurate and detailed.\n",
    "\n",
    "Ensure that your responses are well-structured and directly address the user's query. If the information is not available in the provided documents, state that clearly.'''\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    SystemMessage(content=system_prompt),\n",
    "                    MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "                    HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "                    MessagesPlaceholder(variable_name='agent_scratchpad')\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=document_store,\n",
    ")\n",
    "\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=document_store,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x16c493fdf60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import StructuredTool\n",
    "from llama_index.core.retrievers import VectorIndexAutoRetriever\n",
    "from llama_index.core.vector_stores.types import MetadataInfo, VectorStoreInfo\n",
    "from llama_index.core.vector_stores.types import VectorStoreQuerySpec\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, Dict\n",
    "\n",
    "\n",
    "# Step 2: Define the metadata and vector store information\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"Metadata of Bhaiya & Company 2023.pdf\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"file_path\",\n",
    "            type=\"str\",\n",
    "            description=\"The path where the file is stored\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"file_name\",\n",
    "            type=\"str\",\n",
    "            description=\"The name of the file\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"original_file_name\",\n",
    "            type=\"str\",\n",
    "            description=\"The original name of the file before processing\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"file_size\",\n",
    "            type=\"int\",\n",
    "            description=\"The size of the file (in bytes), can be null\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"author\",\n",
    "            type=\"str\",\n",
    "            description=\"The author of the file, can be null\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"file_tags\",\n",
    "            type=\"list\",\n",
    "            description=\"Tags associated with the file, can be null\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"product_name\",\n",
    "            type=\"list\",\n",
    "            description=\"List of product names associated with the file\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"section\",\n",
    "            type=\"list\",\n",
    "            description=\"List of sections associated with the file\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"type_of_product\",\n",
    "            type=\"list\",\n",
    "            description=\"The types of products mentioned in the file\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"file_web_link\",\n",
    "            type=\"str\",\n",
    "            description=\"A web link to the file\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"parsed_with\",\n",
    "            type=\"str\",\n",
    "            description=\"The tool used to parse the file\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"year\",\n",
    "            type=\"int\",\n",
    "            description=\"The year the file was created or relevant to\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# # Assuming `index` is already defined elsewhere and contains the vector data\n",
    "\n",
    "# # Step 3: Update the tool function to handle both query and filters\n",
    "# def retrieve_metadata(query: str, filters: Optional[Dict] = None):\n",
    "#     if filters is None:\n",
    "#         filters = []  # Set to an empty dictionary if None\n",
    "#     retriever = VectorIndexAutoRetriever(index, vector_store_info=vector_store_info)\n",
    "#     query_spec = VectorStoreQuerySpec(query=query, filters=filters)\n",
    "#     return retriever.retrieve(query_spec)\n",
    "\n",
    "# # Step 4: Create the tool using StructuredTool\n",
    "# metadata_retrieval_tool = StructuredTool(\n",
    "#     name=\"bhaiya_company_metadata_retriever\",  # Valid tool name\n",
    "#     func=retrieve_metadata,\n",
    "#     description=\"Retrieve metadata related to Bhaiya & Company 2023.pdf based on user queries\",\n",
    "#     args_schema=RetrieveMetadataInput  # Use the structured input model\n",
    "# )\n",
    "\n",
    "# # Now you can add this tool to your agent's toolset and use it as part of the Langchain agent execution\n",
    "# tools = [metadata_retrieval_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-index-vector-stores-elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexAutoRetriever\n",
    "from llama_index.core.vector_stores.types import MetadataInfo, VectorStoreInfo\n",
    "\n",
    "\n",
    "\n",
    "retriever = VectorIndexAutoRetriever(\n",
    "    index, vector_store_info=vector_store_info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'about bhaiya and company Sales and Profit Forecast for 2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for VectorStoreQuerySpec\nquery\n  field required (type=value_error.missing)\nfilters\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:260\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    253\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    254\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\base\\base_retriever.py:243\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mas_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    240\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mRETRIEVE,\n\u001b[0;32m    241\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    242\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[1;32m--> 243\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_recursive_retrieval(query_bundle, nodes)\n\u001b[0;32m    245\u001b[0m         retrieve_event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[0;32m    246\u001b[0m             payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes},\n\u001b[0;32m    247\u001b[0m         )\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:260\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    253\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    254\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\base\\base_auto_retriever.py:35\u001b[0m, in \u001b[0;36mBaseAutoRetriever._retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[NodeWithScore]:\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve using generated spec.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     retrieval_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_retrieval_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     retriever, new_query_bundle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_retriever_from_spec(retrieval_spec)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retriever\u001b[38;5;241m.\u001b[39mretrieve(new_query_bundle)\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:260\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    253\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    254\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\auto_retriever\\auto_retriever.py:187\u001b[0m, in \u001b[0;36mVectorIndexAutoRetriever.generate_retrieval_spec\u001b[1;34m(self, query_bundle, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prompt,\n\u001b[0;32m    181\u001b[0m     schema_str\u001b[38;5;241m=\u001b[39mschema_str,\n\u001b[0;32m    182\u001b[0m     info_str\u001b[38;5;241m=\u001b[39minfo_str,\n\u001b[0;32m    183\u001b[0m     query_str\u001b[38;5;241m=\u001b[39mquery_bundle\u001b[38;5;241m.\u001b[39mquery_str,\n\u001b[0;32m    184\u001b[0m )\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# parse output\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_generated_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\auto_retriever\\auto_retriever.py:158\u001b[0m, in \u001b[0;36mVectorIndexAutoRetriever._parse_generated_spec\u001b[1;34m(self, output, query_bundle)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse generated spec.\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    157\u001b[0m     structured_output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m--> 158\u001b[0m         StructuredOutput, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m     query_spec \u001b[38;5;241m=\u001b[39m cast(VectorStoreQuerySpec, structured_output\u001b[38;5;241m.\u001b[39mparsed_output)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException:\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:260\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    253\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    254\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\auto_retriever\\output_parser.py:12\u001b[0m, in \u001b[0;36mVectorStoreQueryOutputParser.parse\u001b[1;34m(self, output)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, output: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     11\u001b[0m     json_dict \u001b[38;5;241m=\u001b[39m parse_json_markdown(output)\n\u001b[1;32m---> 12\u001b[0m     query_and_filters \u001b[38;5;241m=\u001b[39m \u001b[43mVectorStoreQuerySpec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StructuredOutput(raw_output\u001b[38;5;241m=\u001b[39moutput, parsed_output\u001b[38;5;241m=\u001b[39mquery_and_filters)\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\pydantic\\main.py:526\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.parse_obj\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for VectorStoreQuerySpec\nquery\n  field required (type=value_error.missing)\nfilters\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "retriever.retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor  = AgentExecutor(\n",
    "            agent=agent,\n",
    "            tools=tools,\n",
    "            verbose=True,\n",
    "            # max_iterations=5,\n",
    "            handle_parsing_errors=True,\n",
    "            return_intermediate_steps=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"A bunch of scientists bring back dinosaurs and mayhem breaks\"\n",
    "            \" loose\"\n",
    "        ),\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"Leo DiCaprio gets lost in a dream within a dream within a dream\"\n",
    "            \" within a ...\"\n",
    "        ),\n",
    "        metadata={\n",
    "            \"year\": 2010,\n",
    "            \"director\": \"Christopher Nolan\",\n",
    "            \"rating\": 8.2,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"A psychologist / detective gets lost in a series of dreams within\"\n",
    "            \" dreams within dreams and Inception reused the idea\"\n",
    "        ),\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"A bunch of normal-sized women are supremely wholesome and some\"\n",
    "            \" men pine after them\"\n",
    "        ),\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x16c493fdf60>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextNode(id_='c92f639c-26f8-4fcf-8e49-ecbd8ec571ca', embedding=None, metadata={'year': 1993, 'rating': 7.7, 'genre': 'science fiction'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='A bunch of scientists bring back dinosaurs and mayhem breaks loose', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " TextNode(id_='08d665c0-2a37-4d74-9b13-36241e58820c', embedding=None, metadata={'year': 2010, 'director': 'Christopher Nolan', 'rating': 8.2}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " TextNode(id_='7eb1fba0-e97f-48b5-bd99-850795cf1e64', embedding=None, metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " TextNode(id_='68c1cd2c-32a8-4937-9824-4a608beca397', embedding=None, metadata={'year': 2019, 'director': 'Greta Gerwig', 'rating': 8.3}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='A bunch of normal-sized women are supremely wholesome and some men pine after them', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " TextNode(id_='bf7570a3-b0c2-4a51-ac22-13982f9e719e', embedding=None, metadata={'year': 1995, 'genre': 'animated'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Toys come alive and have a blast doing so', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.elasticsearch import ElasticsearchStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"A bunch of scientists bring back dinosaurs and mayhem breaks\"\n",
    "            \" loose\"\n",
    "        ),\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"Leo DiCaprio gets lost in a dream within a dream within a dream\"\n",
    "            \" within a ...\"\n",
    "        ),\n",
    "        metadata={\n",
    "            \"year\": 2010,\n",
    "            \"director\": \"Christopher Nolan\",\n",
    "            \"rating\": 8.2,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"A psychologist / detective gets lost in a series of dreams within\"\n",
    "            \" dreams within dreams and Inception reused the idea\"\n",
    "        ),\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"A bunch of normal-sized women are supremely wholesome and some\"\n",
    "            \" men pine after them\"\n",
    "        ),\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:GET http://localhost:9200/ [status:200 duration:0.209s]\n",
      "GET http://localhost:9200/ [status:200 duration:0.209s]\n"
     ]
    }
   ],
   "source": [
    "vector_store = ElasticsearchStore(\n",
    "    index_name=\"auto_retriever_movies\", es_url=\"http://localhost:9200\"\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:elastic_transport.transport:HEAD http://localhost:9200/auto_retriever_movies [status:200 duration:0.016s]\n",
      "HEAD http://localhost:9200/auto_retriever_movies [status:200 duration:0.016s]\n",
      "INFO:elastic_transport.transport:PUT http://localhost:9200/_bulk?refresh=true [status:200 duration:0.125s]\n",
      "PUT http://localhost:9200/_bulk?refresh=true [status:200 duration:0.125s]\n",
      "INFO:elastic_transport.transport:PUT http://localhost:9200/_bulk?refresh=true [status:200 duration:0.078s]\n",
      "PUT http://localhost:9200/_bulk?refresh=true [status:200 duration:0.078s]\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    ")\n",
    "\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"year\", operator=FilterOperator.EQ, value=\"2019\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:elastic_transport.transport:POST http://localhost:9200/auto_retriever_movies/_search [status:200 duration:0.078s]\n",
      "POST http://localhost:9200/auto_retriever_movies/_search [status:200 duration:0.078s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = index.as_retriever(filters=filters)\n",
    "retriever.retrieve(\"movie ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = VectorIndexAutoRetriever(\n",
    "    index, vector_store_info=vector_store_info, extra_filters=filters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using query str: movies by Christopher Nolan\n",
      "Using query str: movies by Christopher Nolan\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using filters: [('year', '<', '2020'), ('director', '==', 'Christopher Nolan')]\n",
      "Using filters: [('year', '<', '2020'), ('director', '==', 'Christopher Nolan')]\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using top_k: 2\n",
      "Using top_k: 2\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Vector Store only supports exact match filters. Please use ExactMatchFilter or FilterOperator.EQ instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat are 2 movies by Christopher Nolan were made before 2020?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:260\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    253\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    254\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\base\\base_retriever.py:243\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mas_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    240\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mRETRIEVE,\n\u001b[0;32m    241\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    242\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[1;32m--> 243\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_recursive_retrieval(query_bundle, nodes)\n\u001b[0;32m    245\u001b[0m         retrieve_event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[0;32m    246\u001b[0m             payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes},\n\u001b[0;32m    247\u001b[0m         )\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:260\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    253\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    254\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\base\\base_auto_retriever.py:37\u001b[0m, in \u001b[0;36mBaseAutoRetriever._retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m     35\u001b[0m retrieval_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_retrieval_spec(query_bundle)\n\u001b[0;32m     36\u001b[0m retriever, new_query_bundle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_retriever_from_spec(retrieval_spec)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:260\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    253\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    254\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\base\\base_retriever.py:243\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mas_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    240\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mRETRIEVE,\n\u001b[0;32m    241\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    242\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[1;32m--> 243\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_recursive_retrieval(query_bundle, nodes)\n\u001b[0;32m    245\u001b[0m         retrieve_event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[0;32m    246\u001b[0m             payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes},\n\u001b[0;32m    247\u001b[0m         )\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:260\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    253\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    254\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\retriever.py:101\u001b[0m, in \u001b[0;36mVectorIndexRetriever._retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_bundle\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query_bundle\u001b[38;5;241m.\u001b[39membedding_strs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     96\u001b[0m         query_bundle\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     97\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model\u001b[38;5;241m.\u001b[39mget_agg_embedding_from_queries(\n\u001b[0;32m     98\u001b[0m                 query_bundle\u001b[38;5;241m.\u001b[39membedding_strs\n\u001b[0;32m     99\u001b[0m             )\n\u001b[0;32m    100\u001b[0m         )\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_nodes_with_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\retriever.py:177\u001b[0m, in \u001b[0;36mVectorIndexRetriever._get_nodes_with_embeddings\u001b[1;34m(self, query_bundle_with_embeddings)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_nodes_with_embeddings\u001b[39m(\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m, query_bundle_with_embeddings: QueryBundle\n\u001b[0;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[NodeWithScore]:\n\u001b[0;32m    176\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_vector_store_query(query_bundle_with_embeddings)\n\u001b[1;32m--> 177\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mquery(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_node_list_from_query_result(query_result)\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\vector_stores\\elasticsearch\\base.py:502\u001b[0m, in \u001b[0;36mElasticsearchStore.query\u001b[1;34m(self, query, custom_query, es_filter, **kwargs)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    476\u001b[0m     query: VectorStoreQuery,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    482\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VectorStoreQueryResult:\n\u001b[0;32m    483\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Query index for top k most similar nodes.\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \n\u001b[0;32m    485\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    500\u001b[0m \n\u001b[0;32m    501\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mes_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\tasks.py:232\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    234\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\vector_stores\\elasticsearch\\base.py:538\u001b[0m, in \u001b[0;36mElasticsearchStore.aquery\u001b[1;34m(self, query, custom_query, es_filter, **kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m cast(List[\u001b[38;5;28mfloat\u001b[39m], query\u001b[38;5;241m.\u001b[39mquery_embedding)\n\u001b[0;32m    536\u001b[0m es_query \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy_filters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;241m=\u001b[39m [_to_elasticsearch_filter(query\u001b[38;5;241m.\u001b[39mfilters)]\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\virtual_envs\\nia_env\\lib\\site-packages\\llama_index\\core\\vector_stores\\types.py:183\u001b[0m, in \u001b[0;36mMetadataFilters.legacy_filters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m.\u001b[39moperator \u001b[38;5;241m!=\u001b[39m FilterOperator\u001b[38;5;241m.\u001b[39mEQ:\n\u001b[1;32m--> 183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVector Store only supports exact match filters. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    185\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use ExactMatchFilter or FilterOperator.EQ instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    186\u001b[0m         )\n\u001b[0;32m    187\u001b[0m     filters\u001b[38;5;241m.\u001b[39mappend(ExactMatchFilter(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m.\u001b[39mkey, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m.\u001b[39mvalue))\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filters\n",
      "\u001b[1;31mValueError\u001b[0m: Vector Store only supports exact match filters. Please use ExactMatchFilter or FilterOperator.EQ instead."
     ]
    }
   ],
   "source": [
    "retriever.retrieve(\n",
    "    \"What are 2 movies by Christopher Nolan were made before 2020?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
